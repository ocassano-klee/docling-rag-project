# Configuration Cohere Embeddings

## Vue d'ensemble

Ce projet utilise **Cohere embed-multilingual-v3**, un mod√®le d'embeddings de haute qualit√© optimis√© pour le multilinguisme, incluant le fran√ßais.

### Avantages de Cohere embed-multilingual-v3

- ‚úÖ **Multilingue** : Excellent support pour le fran√ßais et 100+ langues
- ‚úÖ **Haute qualit√©** : Performance sup√©rieure aux mod√®les open-source
- ‚úÖ **Dimension 1024** : Repr√©sentations vectorielles riches
- ‚úÖ **Optimis√© pour RAG** : Deux modes (search_document et search_query)
- ‚úÖ **Scalable** : API cloud, pas besoin de GPU local

### Caract√©ristiques techniques

- **Mod√®le** : `embed-multilingual-v3`
- **Dimension** : 1024
- **Langues** : 100+ (dont fran√ßais, anglais, espagnol, etc.)
- **Batch size** : Jusqu'√† 96 textes par requ√™te
- **Input types** :
  - `search_document` : Pour indexer les documents
  - `search_query` : Pour les requ√™tes utilisateur

## Installation

### 1. Installer la biblioth√®que Cohere

```bash
pip install cohere>=5.0.0
```

### 2. Obtenir une cl√© API

1. Cr√©er un compte sur [Cohere](https://cohere.com/)
2. Aller dans [Dashboard > API Keys](https://dashboard.cohere.com/api-keys)
3. Cr√©er une nouvelle cl√© API (Production ou Trial)

### 3. Configurer la cl√© API

**Option A : Variable d'environnement (recommand√©)**

```bash
# Linux/Mac
export COHERE_API_KEY="votre-cle-api"

# Windows CMD
set COHERE_API_KEY=votre-cle-api

# Windows PowerShell
$env:COHERE_API_KEY="votre-cle-api"
```

**Option B : Fichier de configuration**

√âditer `config.yaml` :

```yaml
embeddings:
  provider: "cohere"
  model: "embed-multilingual-v3"
  dimension: 1024
  batch_size: 96
  api_key: "votre-cle-api"  # ‚ö†Ô∏è Ne pas commiter ce fichier !
```

**Option C : Fichier .env**

Cr√©er un fichier `.env` √† la racine :

```bash
COHERE_API_KEY=votre-cle-api
```

Puis charger avec python-dotenv :

```bash
pip install python-dotenv
```

```python
from dotenv import load_dotenv
load_dotenv()
```

## Configuration

### Configuration de base

```yaml
# config.yaml
embeddings:
  provider: "cohere"
  model: "embed-multilingual-v3"
  dimension: 1024
  batch_size: 96
  api_key: ""  # Laisser vide si utilisation de variable d'environnement
```

### Configuration OpenSearch

Mettre √† jour la dimension dans OpenSearch :

```yaml
opensearch:
  endpoint: "https://your-domain.es.amazonaws.com"
  index_name: "document-chunks"
```

L'index sera cr√©√© automatiquement avec la bonne dimension (1024).

## Utilisation

### Ingestion de documents

```bash
# Avec variable d'environnement
export COHERE_API_KEY="votre-cle"
python src/ingestion.py --input data/input/document.pdf

# Ou avec cl√© dans config.yaml
python src/ingestion.py --input data/input/document.pdf
```

Le syst√®me utilisera automatiquement `input_type="search_document"` pour l'indexation.

### Interrogation

```bash
python src/query.py --question "Qu'est-ce qu'un Data Fabric?"
```

Le syst√®me utilisera automatiquement `input_type="search_query"` pour les questions.

## Diff√©rences avec sentence-transformers

### Avant (sentence-transformers)

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')
embedding = model.encode("texte")  # 384 dimensions
```

### Apr√®s (Cohere)

```python
import cohere

client = cohere.Client(api_key)
response = client.embed(
    texts=["texte"],
    model="embed-multilingual-v3",
    input_type="search_document"
)
embedding = response.embeddings.float[0]  # 1024 dimensions
```

## Tarification Cohere

### Plan gratuit (Trial)

- ‚úÖ 100 requ√™tes API / minute
- ‚úÖ Id√©al pour d√©veloppement et tests
- ‚úÖ Pas de carte de cr√©dit requise

### Plan Production

- üí∞ ~$0.10 / 1000 embeddings
- üìä Exemple : 10,000 chunks = ~$1.00
- üöÄ Rate limits plus √©lev√©s

### Estimation de co√ªts

```
Document de 100 pages
‚Üí ~200 chunks
‚Üí ~$0.02 pour l'ingestion

1000 questions
‚Üí 1000 embeddings de requ√™te
‚Üí ~$0.10

Total pour un document + 1000 questions : ~$0.12
```

## Performance

### Vitesse

- **API Cohere** : ~100-200 embeddings/sec
- **Batch de 96** : Optimal pour throughput
- **Latence** : ~100-300ms par requ√™te

### Qualit√©

Cohere embed-multilingual-v3 surpasse g√©n√©ralement :
- sentence-transformers/all-MiniLM-L6-v2
- sentence-transformers/paraphrase-multilingual-mpnet-base-v2

Particuli√®rement pour :
- ‚úÖ Textes en fran√ßais
- ‚úÖ Textes multilingues
- ‚úÖ Recherche s√©mantique cross-lingue

## Comparaison des mod√®les

| Mod√®le | Dimension | Langues | Qualit√© | Co√ªt | Local |
|--------|-----------|---------|---------|------|-------|
| **Cohere embed-multilingual-v3** | 1024 | 100+ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | API | ‚ùå |
| all-MiniLM-L6-v2 | 384 | EN | ‚≠ê‚≠ê‚≠ê | Gratuit | ‚úÖ |
| paraphrase-multilingual-mpnet | 768 | 50+ | ‚≠ê‚≠ê‚≠ê‚≠ê | Gratuit | ‚úÖ |
| OpenAI text-embedding-ada-002 | 1536 | 100+ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | API | ‚ùå |

## D√©pannage

### Erreur : "API key not found"

**Solution** :

```bash
# V√©rifier la variable d'environnement
echo $COHERE_API_KEY

# Si vide, d√©finir
export COHERE_API_KEY="votre-cle"
```

### Erreur : "Rate limit exceeded"

**Cause** : Trop de requ√™tes

**Solutions** :

1. R√©duire le batch_size :
```yaml
embeddings:
  batch_size: 48  # Au lieu de 96
```

2. Ajouter des pauses :
```python
import time
time.sleep(1)  # Entre les batchs
```

3. Passer au plan Production

### Erreur : "Invalid API key"

**Solutions** :

1. V√©rifier la cl√© sur [dashboard.cohere.com](https://dashboard.cohere.com/api-keys)
2. R√©g√©n√©rer une nouvelle cl√©
3. V√©rifier qu'il n'y a pas d'espaces dans la cl√©

### Embeddings de mauvaise qualit√©

**Solutions** :

1. V√©rifier que vous utilisez bien `embed-multilingual-v3` (pas v2)
2. S'assurer que `input_type` est correct :
   - `search_document` pour l'ingestion
   - `search_query` pour les questions

## Migration depuis sentence-transformers

### √âtape 1 : Mettre √† jour requirements.txt

```bash
# Remplacer
sentence-transformers>=2.2.0

# Par
cohere>=5.0.0
```

### √âtape 2 : Mettre √† jour config.yaml

```yaml
embeddings:
  provider: "cohere"  # Ajouter
  model: "embed-multilingual-v3"  # Changer
  dimension: 1024  # Changer de 384 √† 1024
  batch_size: 96  # Changer de 32 √† 96
  api_key: ""  # Ajouter
```

### √âtape 3 : Recr√©er l'index OpenSearch

```python
from opensearch_client import OpenSearchClient

client = OpenSearchClient(...)

# Supprimer l'ancien index
client.client.indices.delete(index="document-chunks")

# Cr√©er le nouveau avec dimension 1024
client.create_index(dimension=1024)
```

### √âtape 4 : R√©-ing√©rer les documents

```bash
# Tous les documents doivent √™tre r√©-ing√©r√©s avec les nouveaux embeddings
python src/ingestion.py --input data/input/document.pdf
```

## Alternatives

Si vous pr√©f√©rez rester en local (sans API) :

### Option 1 : sentence-transformers multilingue

```yaml
embeddings:
  provider: "sentence-transformers"
  model: "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
  dimension: 768
  batch_size: 32
```

### Option 2 : Mod√®le fran√ßais sp√©cialis√©

```yaml
embeddings:
  provider: "sentence-transformers"
  model: "dangvantuan/sentence-camembert-large"
  dimension: 768
  batch_size: 32
```

## Ressources

- [Documentation Cohere Embed](https://docs.cohere.com/docs/embeddings)
- [Cohere Dashboard](https://dashboard.cohere.com/)
- [Cohere Pricing](https://cohere.com/pricing)
- [Guide des mod√®les d'embeddings](https://txt.cohere.com/introducing-embed-v3/)

## Support

Pour des questions sur Cohere :
- [Discord Cohere](https://discord.gg/cohere)
- [Support Cohere](https://cohere.com/support)
