# Changelog

## Version 1.1.0 - Migration vers Cohere Embeddings

### üéØ Changements majeurs

#### Mod√®le d'embeddings

**Avant** : sentence-transformers/all-MiniLM-L6-v2
- Dimension : 384
- Local (CPU/GPU)
- Gratuit
- Qualit√© moyenne pour le fran√ßais

**Apr√®s** : Cohere embed-multilingual-v3
- Dimension : 1024
- API cloud
- ~$0.10 / 1000 embeddings
- Excellente qualit√© pour le fran√ßais et 100+ langues

### üìù Fichiers modifi√©s

#### requirements.txt
```diff
- sentence-transformers>=2.2.0
+ cohere>=5.0.0
```

#### config.yaml
```diff
  embeddings:
-   model: "sentence-transformers/all-MiniLM-L6-v2"
-   dimension: 384
-   batch_size: 32
+   provider: "cohere"
+   model: "embed-multilingual-v3"
+   dimension: 1024
+   batch_size: 96
+   api_key: ""
```

#### src/embeddings.py
- ‚úÖ Ajout du support Cohere
- ‚úÖ Gestion des input_types (`search_document` et `search_query`)
- ‚úÖ Batch processing jusqu'√† 96 textes
- ‚úÖ Fallback sur sentence-transformers si besoin
- ‚úÖ Gestion de la cl√© API (param√®tre ou variable d'environnement)

#### src/ingestion.py
```diff
  self.embeddings = EmbeddingGenerator(
-     model_name=self.config['embeddings']['model']
+     provider=self.config['embeddings']['provider'],
+     model_name=self.config['embeddings']['model'],
+     api_key=self.config['embeddings'].get('api_key')
  )
```

#### src/query.py
```diff
  self.embeddings = EmbeddingGenerator(
-     model_name=self.config['embeddings']['model']
+     provider=self.config['embeddings']['provider'],
+     model_name=self.config['embeddings']['model'],
+     api_key=self.config['embeddings'].get('api_key')
  )
  
  # Utilisation de input_type pour les requ√™tes
- question_embedding = self.embeddings.generate_embedding(question)
+ question_embedding = self.embeddings.generate_embedding(question, input_type="search_query")
```

### üìö Documentation ajout√©e

#### Nouveaux fichiers
- ‚úÖ **COHERE_SETUP.md** : Guide complet de configuration Cohere
  - Obtention de la cl√© API
  - Configuration (3 m√©thodes)
  - Tarification et co√ªts
  - Comparaison avec alternatives
  - D√©pannage sp√©cifique Cohere
  - Migration depuis sentence-transformers

- ‚úÖ **QUICK_REFERENCE.md** : R√©f√©rence rapide
  - Commandes essentielles
  - Configuration minimale
  - V√©rifications rapides
  - D√©pannage express

#### Fichiers mis √† jour
- ‚úÖ **README.md** : Mention de Cohere et lien vers COHERE_SETUP.md
- ‚úÖ **ARCHITECTURE.md** : Section embeddings mise √† jour avec Cohere
- ‚úÖ **GETTING_STARTED.md** : Ajout de l'√©tape configuration Cohere
- ‚úÖ **PROJECT_SUMMARY.md** : Mise √† jour des caract√©ristiques

### üîß Nouvelles fonctionnalit√©s

#### Input types Cohere
```python
# Pour l'ingestion (documents)
embeddings.generate_embedding(text, input_type="search_document")

# Pour les requ√™tes (questions)
embeddings.generate_embedding(text, input_type="search_query")
```

#### Support multi-provider
```yaml
# Cohere (par d√©faut)
embeddings:
  provider: "cohere"
  model: "embed-multilingual-v3"

# Ou sentence-transformers (fallback)
embeddings:
  provider: "sentence-transformers"
  model: "sentence-transformers/all-MiniLM-L6-v2"
```

### ‚öôÔ∏è Configuration requise

#### Variables d'environnement
```bash
export COHERE_API_KEY="votre-cle-api"
```

#### Ou dans config.yaml
```yaml
embeddings:
  api_key: "votre-cle-api"
```

### üîÑ Migration depuis version 1.0.0

#### √âtape 1 : Mettre √† jour les d√©pendances
```bash
pip install cohere>=5.0.0
```

#### √âtape 2 : Obtenir une cl√© API Cohere
1. Cr√©er un compte sur [cohere.com](https://cohere.com/)
2. Obtenir une cl√© sur [dashboard.cohere.com/api-keys](https://dashboard.cohere.com/api-keys)
3. `export COHERE_API_KEY="votre-cle"`

#### √âtape 3 : Mettre √† jour config.yaml
```yaml
embeddings:
  provider: "cohere"
  model: "embed-multilingual-v3"
  dimension: 1024
  batch_size: 96
  api_key: ""
```

#### √âtape 4 : Recr√©er l'index OpenSearch
```python
from opensearch_client import OpenSearchClient

client = OpenSearchClient(...)
client.client.indices.delete(index="document-chunks")
client.create_index(dimension=1024)
```

#### √âtape 5 : R√©-ing√©rer les documents
```bash
# Tous les documents doivent √™tre r√©-ing√©r√©s
python src/ingestion.py --input data/input/document.pdf
```

### üìä Comparaison des performances

| M√©trique | v1.0.0 (sentence-transformers) | v1.1.0 (Cohere) |
|----------|-------------------------------|-----------------|
| Dimension | 384 | 1024 |
| Qualit√© (fran√ßais) | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Vitesse | ~1000/sec (CPU) | ~100-200/sec (API) |
| Co√ªt | Gratuit | ~$0.10 / 1000 |
| Infrastructure | Local (GPU recommand√©) | Cloud (API) |
| Multilingue | Limit√© | Excellent (100+ langues) |

### üí∞ Estimation des co√ªts

#### Ingestion
- 100 pages PDF ‚Üí ~200 chunks ‚Üí ~$0.02
- 1000 pages PDF ‚Üí ~2000 chunks ‚Üí ~$0.20

#### Interrogation
- 1000 questions ‚Üí ~$0.10

#### Total exemple
- 10 documents (1000 pages) + 1000 questions ‚Üí ~$0.30

### ‚ö†Ô∏è Breaking Changes

1. **Dimension des embeddings** : 384 ‚Üí 1024
   - N√©cessite de recr√©er l'index OpenSearch
   - N√©cessite de r√©-ing√©rer tous les documents

2. **Configuration** : Nouveau format
   - Ajout du champ `provider`
   - Ajout du champ `api_key`
   - Changement de `batch_size` (32 ‚Üí 96)

3. **D√©pendances** : Nouvelle biblioth√®que
   - `sentence-transformers` ‚Üí `cohere`

### ‚úÖ R√©trocompatibilit√©

Le code supporte toujours sentence-transformers en fallback :

```yaml
embeddings:
  provider: "sentence-transformers"
  model: "sentence-transformers/all-MiniLM-L6-v2"
  dimension: 384
  batch_size: 32
```

### üêõ Corrections

- Aucune correction de bug dans cette version (nouvelle fonctionnalit√©)

### üìñ Documentation

7 fichiers de documentation au total :
1. README.md (mis √† jour)
2. GETTING_STARTED.md (mis √† jour)
3. COHERE_SETUP.md (nouveau)
4. QUICK_REFERENCE.md (nouveau)
5. ARCHITECTURE.md (mis √† jour)
6. EXAMPLES.md (inchang√©)
7. TROUBLESHOOTING.md (inchang√©)

### üéì Prochaines √©tapes recommand√©es

1. ‚úÖ Lire [COHERE_SETUP.md](COHERE_SETUP.md)
2. ‚úÖ Obtenir une cl√© API Cohere
3. ‚úÖ Tester en mode dry-run
4. ‚úÖ Migrer vos donn√©es existantes
5. ‚¨ú √âvaluer la qualit√© des r√©sultats
6. ‚¨ú Optimiser les param√®tres si n√©cessaire

---

## Version 1.0.0 - Version initiale

### Fonctionnalit√©s

- ‚úÖ Ingestion de PDFs avec Docling
- ‚úÖ Chunking intelligent
- ‚úÖ Annotations contextuelles
- ‚úÖ Stockage dans Neptune
- ‚úÖ Embeddings avec sentence-transformers
- ‚úÖ Indexation dans OpenSearch
- ‚úÖ Recherche de similarit√©
- ‚úÖ G√©n√©ration de prompts augment√©s
- ‚úÖ Mode dry-run
- ‚úÖ Documentation compl√®te


---

## Version 2.0.0 - Graphe de connaissances interconnect√©

### üéØ Nouveaut√©s majeures

#### 1. Extraction automatique de topics
- **Identification de concepts** : Extraction automatique de concepts m√©tier et mots-cl√©s depuis chaque chunk
- **17 concepts m√©tier pr√©d√©finis** : assurance, remboursement, dentaire, sant√©, intervention, mutuelle, contrat, plafond, prestation, b√©n√©ficiaire, facture, paiement, compte, client, document, p√©riode, montant
- **Scoring intelligent** : Les concepts m√©tier ont un score plus √©lev√© que les mots-cl√©s simples
- **Normalisation** : Les topics sont normalis√©s pour √©viter les doublons (accents, casse, etc.)

#### 2. Graphe interconnect√© via topics partag√©s
- **N≈ìuds Topic partag√©s** : Utilisation de `MERGE` au lieu de `CREATE` dans Neptune
- **Relations ABOUT** : Chaque chunk est li√© aux topics qu'il contient
- **Liaison automatique** : Les documents partageant des topics sont automatiquement connect√©s
- **Navigation contextuelle** : Possibilit√© de naviguer entre documents via concepts communs

#### 3. Extraction de tables
- **D√©tection automatique** : Docling identifie les tables dans les PDFs
- **Extraction du contenu** : Le texte des cellules est extrait et format√©
- **Chunking des tables** : Les tables sont trait√©es comme des chunks sp√©ciaux
- **Support multi-pages** : Gestion des tables r√©parties sur plusieurs pages

#### 4. Visualisation du graphe Neptune
- **Image PNG automatique** : G√©n√©ration d'une visualisation √† chaque ingestion
- **Couleurs par type** :
  - Rouge : Documents
  - Bleu : Chunks
  - Jaune : Topics (partag√©s)
  - Vert : Annotations
- **Layout hi√©rarchique** : Organisation claire sur 4 niveaux
- **Statistiques** : Affichage du nombre de n≈ìuds et relations
- **Haute r√©solution** : Export en 300 DPI

#### 5. Visualisation interactive (Graph Viewer)
- **Outil HTML interactif** : `dry_run_output/viewer/generate_graph_viewer.py`
- **Lecture multi-CSV** : Parse tous les fichiers `neptune_inserts_*.csv`
- **Identification des topics partag√©s** : D√©tecte automatiquement les topics li√©s √† plusieurs documents
- **Navigation interactive** : Zoom, pan, s√©lection de n≈ìuds avec vis.js
- **Layouts multiples** : Hi√©rarchique, force-directed, circulaire
- **Statistiques en temps r√©el** : Nombre de documents, chunks, topics, relations
- **Focus automatique** : Bouton pour zoomer sur les topics partag√©s
- **Documentation compl√®te** : README.md et USAGE_GUIDE.md dans le dossier viewer

#### 6. Traitement batch de plusieurs PDFs
- **Nommage intelligent** : Chaque document g√©n√®re ses propres fichiers (`{doc_name}.csv`, `{doc_name}.png`)
- **Scripts batch** : `batch_ingestion.sh` (Linux/Mac) et `batch_ingestion.bat` (Windows)
- **Pas d'√©crasement** : Les sorties pr√©c√©dentes sont pr√©serv√©es
- **Progression** : Affichage de la progression (1/N, 2/N, etc.)

### üîß Am√©liorations techniques

#### Extraction PDF
- **Correction majeure** : Utilisation de `doc.iterate_items()` au lieu de `for item in doc.body`
- **Fallback robuste** : Si `iterate_items()` ne retourne rien, utilisation de `export_to_text()`
- **Support des tables** : M√©thode `_extract_table_text()` pour extraire le contenu des tables
- **Gestion des pages** : Meilleure d√©tection du num√©ro de page via `prov_item.page_no`

#### Pipeline d'ingestion
- **6 √©tapes** au lieu de 5 :
  1. Extraction et chunking avec Docling
  2. G√©n√©ration des embeddings
  3. **üÜï Extraction des topics et concepts**
  4. Insertion dans Neptune
  5. Insertion dans OpenSearch
  6. Export/Visualisation
- **Logs am√©lior√©s** : Affichage du nombre de topics identifi√©s

#### Configuration
- **Mod√®le Cohere corrig√©** : `embed-multilingual-v3.0` au lieu de `embed-multilingual-v3`
- **D√©pendances ajout√©es** : `networkx>=3.0` et `matplotlib>=3.7.0`

### üìö Documentation

#### Nouveaux fichiers
- **TOPICS_LINKING.md** : Guide complet sur la liaison des documents via topics (exemples, requ√™tes Cypher, cas d'usage)
- **BATCH_PROCESSING.md** : Guide pour le traitement de plusieurs PDFs (scripts, organisation, d√©pannage)
- **WHATS_NEW_V2.md** : R√©sum√© convivial des nouveaut√©s de la v2.0
- **src/topic_extractor.py** : Module d'extraction de topics (300+ lignes)
- **dry_run_output/viewer/generate_graph_viewer.py** : G√©n√©rateur de visualisation interactive (600+ lignes)
- **dry_run_output/viewer/README.md** : Documentation du Graph Viewer
- **dry_run_output/viewer/USAGE_GUIDE.md** : Guide d'utilisation d√©taill√© du viewer

#### Fichiers mis √† jour
- **README.md** : Ajout section "Nouveaut√©s v2.0", mise √† jour architecture et mod√®le de donn√©es
- **START_HERE.md** : Mise √† jour des fonctionnalit√©s et points forts
- **CHANGELOG.md** : Ce fichier

### üêõ Corrections de bugs

1. **0 chunks g√©n√©r√©s** : Le code utilisait une mauvaise m√©thode pour it√©rer sur `doc.body`
   - Avant : `for item in doc.body` ‚Üí retournait des tuples
   - Apr√®s : `for item, level in doc.iterate_items()` ‚Üí retourne les vrais √©l√©ments

2. **Tables non extraites** : Les tables de la page 2 n'√©taient pas trait√©es
   - Ajout de la d√©tection et extraction des tables via `doc.tables`
   - M√©thode `_extract_table_text()` pour formater le contenu

3. **Import manquant** : `NameError: name 'Set' is not defined`
   - Ajout de `Set` dans les imports de `typing`

4. **Fichiers √©cras√©s** : En mode dry-run, les fichiers √©taient √©cras√©s
   - Ajout du nom du document dans les noms de fichiers

### üìä Statistiques

- **Fichiers ajout√©s** : 3
  - `src/topic_extractor.py` (300+ lignes)
  - `TOPICS_LINKING.md` (200+ lignes)
  - `BATCH_PROCESSING.md` (150+ lignes)

- **Fichiers modifi√©s** : 7
  - `src/ingestion.py` (+200 lignes)
  - `src/docling_processor.py` (+50 lignes)
  - `config.yaml` (1 ligne)
  - `requirements.txt` (+2 lignes)
  - `README.md` (+100 lignes)
  - `START_HERE.md` (+30 lignes)
  - `CHANGELOG.md` (ce fichier)

- **Lignes de code ajout√©es** : ~800
- **Topics extraits (exemple)** : 17 topics uniques depuis un document de 2 pages
- **Chunks g√©n√©r√©s (exemple)** : 6 chunks (4 texte + 2 tables)

### üéì Exemples de requ√™tes Neptune

#### Trouver tous les documents sur un topic
```cypher
MATCH (d:Document)-[:HAS_CHUNK]->(c:Chunk)-[:ABOUT]->(t:Topic {name: 'assurance'})
RETURN DISTINCT d.title
```

#### Trouver les documents similaires
```cypher
MATCH (d1:Document)-[:HAS_CHUNK]->(c1:Chunk)-[:ABOUT]->(t:Topic)<-[:ABOUT]-(c2:Chunk)<-[:HAS_CHUNK]-(d2:Document)
WHERE d1 <> d2
WITH d1, d2, COUNT(DISTINCT t) as common_topics
WHERE common_topics >= 3
RETURN d1.title, d2.title, common_topics
ORDER BY common_topics DESC
```

#### Trouver les topics les plus populaires
```cypher
MATCH (c:Chunk)-[:ABOUT]->(t:Topic)
RETURN t.name, t.type, COUNT(c) as chunk_count
ORDER BY chunk_count DESC
LIMIT 10
```

### üöÄ Migration depuis v1.x

1. Mettre √† jour les d√©pendances :
   ```bash
   pip install -r requirements.txt
   ```

2. Mettre √† jour `config.yaml` :
   ```yaml
   embeddings:
     model: "embed-multilingual-v3.0"  # Ajouter .0
   ```

3. R√©ing√©rer les documents existants pour b√©n√©ficier des topics :
   ```bash
   python src/ingestion.py --input data/input/document.pdf --dry-run
   ```

4. Les anciens documents dans Neptune ne seront pas automatiquement li√©s aux nouveaux topics. Pour une migration compl√®te, il faudrait :
   - Supprimer les anciens documents de Neptune
   - R√©ing√©rer tous les documents avec la v2.0

### ‚ö†Ô∏è Breaking Changes

- **Aucun** : La v2.0 est r√©trocompatible avec la v1.x
- Les anciens documents continuent de fonctionner
- Les nouveaux documents b√©n√©ficient automatiquement des topics

### üîÆ Prochaines √©tapes

- [ ] Extraction d'entit√©s nomm√©es (personnes, organisations, lieux)
- [ ] Liens de similarit√© s√©mantique entre chunks
- [ ] Interface web pour visualiser le graphe
- [ ] Support de plus de types de documents (Word, Excel, etc.)
- [ ] Am√©lioration de l'extraction de topics avec NLP avanc√©
- [ ] Cache des embeddings pour √©viter les recalculs

---

**Date de release** : 16 janvier 2026  
**Contributeurs** : √âquipe de d√©veloppement  
**Compatibilit√©** : Python 3.8+, Neptune, OpenSearch, Cohere API
