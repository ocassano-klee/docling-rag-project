# RÃ©fÃ©rence rapide

## ğŸš€ Commandes essentielles

### Installation

```bash
# CrÃ©er l'environnement
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer
pip install -r requirements.txt

# Configurer Cohere
export COHERE_API_KEY="votre-cle-api"
```

### Ingestion

```bash
# Mode dry-run (test sans AWS)
python src/ingestion.py --input data/input/doc.pdf --dry-run

# Mode rÃ©el
python src/ingestion.py --input data/input/doc.pdf

# Plusieurs documents
for file in data/input/*.pdf; do
    python src/ingestion.py --input "$file"
done
```

### Interrogation

```bash
# Mode dry-run
python src/query.py --question "Votre question?" --dry-run

# Mode rÃ©el
python src/query.py --question "Votre question?"

# Avec filtrage Neptune
python src/query.py --question "Votre question?" --use-neptune-filter
```

## âš™ï¸ Configuration rapide

### config.yaml minimal

```yaml
neptune:
  endpoint: "cluster.neptune.amazonaws.com"
  port: 8182
  region: "eu-west-1"

opensearch:
  endpoint: "https://domain.es.amazonaws.com"
  index_name: "document-chunks"
  region: "eu-west-1"

embeddings:
  provider: "cohere"
  model: "embed-multilingual-v3"
  dimension: 1024
  batch_size: 96
  api_key: ""  # Ou via COHERE_API_KEY

docling:
  chunk_size: 512
  chunk_overlap: 50
  min_chunk_size: 100

query:
  top_k: 5
  similarity_threshold: 0.7
```

## ğŸ“Š ModÃ¨le Cohere

### CaractÃ©ristiques

- **ModÃ¨le** : embed-multilingual-v3
- **Dimension** : 1024
- **Langues** : 100+ (excellent franÃ§ais)
- **Batch max** : 96 textes
- **Tarif** : ~$0.10 / 1000 embeddings

### Obtenir une clÃ© API

1. [cohere.com](https://cohere.com/) â†’ CrÃ©er un compte
2. [dashboard.cohere.com/api-keys](https://dashboard.cohere.com/api-keys) â†’ Nouvelle clÃ©
3. `export COHERE_API_KEY="votre-cle"`

### Input types

```python
# Pour indexer les documents
input_type="search_document"

# Pour les requÃªtes utilisateur
input_type="search_query"
```

## ğŸ—‚ï¸ Structure des fichiers

```
docling-rag-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion.py          # Script principal d'ingestion
â”‚   â”œâ”€â”€ query.py              # Script principal d'interrogation
â”‚   â”œâ”€â”€ docling_processor.py  # Traitement PDF
â”‚   â”œâ”€â”€ embeddings.py         # Embeddings Cohere
â”‚   â”œâ”€â”€ neptune_client.py     # Client Neptune
â”‚   â””â”€â”€ opensearch_client.py  # Client OpenSearch
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/                # PDFs Ã  traiter
â”‚   â””â”€â”€ output/               # Prompts gÃ©nÃ©rÃ©s
â”œâ”€â”€ dry_run_output/           # CSV en mode dry-run
â””â”€â”€ config.yaml               # Configuration
```

## ğŸ” VÃ©rifications rapides

### Tester la connexion Cohere

```python
import cohere
import os

client = cohere.Client(os.getenv("COHERE_API_KEY"))
response = client.embed(
    texts=["test"],
    model="embed-multilingual-v3",
    input_type="search_document"
)
print(f"Dimension: {len(response.embeddings.float[0])}")  # 1024
```

### VÃ©rifier Neptune

```bash
aws neptune describe-db-clusters --query 'DBClusters[*].[DBClusterIdentifier,Endpoint,Status]'
```

### VÃ©rifier OpenSearch

```bash
curl -X GET "https://your-domain.es.amazonaws.com/_cat/indices?v"
```

## ğŸ› DÃ©pannage express

### Erreur : "API key not found"

```bash
export COHERE_API_KEY="votre-cle"
echo $COHERE_API_KEY  # VÃ©rifier
```

### Erreur : "Connection refused" (Neptune)

```bash
# VÃ©rifier endpoint
aws neptune describe-db-clusters

# VÃ©rifier security group (port 8182)
```

### Erreur : "Index not found" (OpenSearch)

```python
from opensearch_client import OpenSearchClient
client = OpenSearchClient(...)
client.create_index(dimension=1024)
```

### Erreur : "Rate limit exceeded" (Cohere)

```yaml
# RÃ©duire batch_size dans config.yaml
embeddings:
  batch_size: 48  # Au lieu de 96
```

## ğŸ“ˆ Workflow typique

```
1. Configuration
   â””â”€ Configurer config.yaml + COHERE_API_KEY

2. Test (dry-run)
   â”œâ”€ python src/ingestion.py --input doc.pdf --dry-run
   â””â”€ python src/query.py --question "test?" --dry-run

3. Ingestion
   â””â”€ python src/ingestion.py --input doc.pdf

4. Interrogation
   â””â”€ python src/query.py --question "Votre question?"

5. Utilisation du prompt
   â””â”€ Copier data/output/prompt_*.txt â†’ Envoyer au LLM
```

## ğŸ“š Documentation

| Fichier | Description |
|---------|-------------|
| [README.md](README.md) | Vue d'ensemble + architecture |
| [GETTING_STARTED.md](GETTING_STARTED.md) | Guide de dÃ©marrage |
| [COHERE_SETUP.md](COHERE_SETUP.md) | Configuration Cohere dÃ©taillÃ©e |
| [ARCHITECTURE.md](ARCHITECTURE.md) | Architecture technique |
| [EXAMPLES.md](EXAMPLES.md) | Exemples d'utilisation |
| [TROUBLESHOOTING.md](TROUBLESHOOTING.md) | Guide de dÃ©pannage |

## ğŸ’¡ Astuces

### Performance

```bash
# Traiter en parallÃ¨le (attention aux rate limits Cohere)
parallel -j 2 python src/ingestion.py --input {} ::: data/input/*.pdf
```

### CoÃ»ts Cohere

```
100 pages PDF â†’ ~200 chunks â†’ ~$0.02
1000 questions â†’ ~$0.10
Total : ~$0.12 pour un document + 1000 questions
```

### QualitÃ© des rÃ©sultats

```yaml
# Augmenter pour plus de contexte
query:
  top_k: 10
  
# Augmenter pour plus de prÃ©cision
docling:
  chunk_size: 256
```

## ğŸ”— Liens utiles

- [Cohere Dashboard](https://dashboard.cohere.com/)
- [Cohere Docs](https://docs.cohere.com/docs/embeddings)
- [AWS Neptune Docs](https://docs.aws.amazon.com/neptune/)
- [AWS OpenSearch Docs](https://docs.aws.amazon.com/opensearch-service/)
